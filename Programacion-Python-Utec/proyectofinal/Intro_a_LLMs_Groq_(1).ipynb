{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgePeje/test-python-utec/blob/main/Programacion-Python-Utec/proyectofinal/Intro_a_LLMs_Groq_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9ab89f5",
      "metadata": {
        "id": "f9ab89f5",
        "outputId": "90f8c81f-2df7-4746-dfaf-3798ece5f3b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.11/dist-packages (0.3.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.3.63)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.26.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.14.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (0.3.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain-groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.49->langchain-groq) (2.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-groq\n",
        "#Paquete de Python\n",
        "#Es un conector oficial entre LangChain y la API de Groq, una empresa que ofrece acceso muy r√°pido a modelos de lenguaje como LLaMA 3.\n",
        "\n",
        "#Permite:\n",
        "#Usar los modelos de Groq (como llama3-8b o llama3-70b) directamente desde LangChain\n",
        "#Integrarlos f√°cilmente en tus cadenas de procesamiento de texto\n",
        "#Hacer chatbots, asistentes, o apps que consulten tus documentos t√©cnicos, como tu manual\n",
        "\n",
        "#Es util porque combina lo mejor de ambos mundos\n",
        "#- LangChain:\tCrear flujos de procesamiento inteligente con lenguaje natural\n",
        "#- Groq:\tAcceder a modelos LLM potentes y ultra r√°pidos (como LLaMA 3)\n",
        "#--> langchain-groq:\tConectar ambos f√°cilmente"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''üìå Desglose\n",
        "! ‚Üí Este s√≠mbolo al inicio indica que se est√° ejecutando un comando de terminal (shell) desde un entorno de notebook. En Python puro (por ejemplo, en scripts .py), no usar√≠as !, pero en Jupyter s√≠.\n",
        "pip install ‚Üí Es el comando est√°ndar de Python para instalar paquetes desde PyPI, el repositorio oficial de paquetes de Python.\n",
        "langchain-groq ‚Üí Es un paquete espec√≠fico que integra LangChain (un framework para construir aplicaciones basadas en modelos de lenguaje) con Groq, una empresa que proporciona hardware ultrarr√°pido para ejecutar modelos como LLaMA, Mixtral, etc.'''"
      ],
      "metadata": {
        "id": "vl2EpN2TPLFP",
        "outputId": "8aac5078-9a8a-4b46-ba9d-7f6b6fde8908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "id": "vl2EpN2TPLFP",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'üìå Desglose\\n! ‚Üí Este s√≠mbolo al inicio indica que se est√° ejecutando un comando de terminal (shell) desde un entorno de notebook. En Python puro (por ejemplo, en scripts .py), no usar√≠as !, pero en Jupyter s√≠.\\n\\npip install ‚Üí Es el comando est√°ndar de Python para instalar paquetes desde PyPI, el repositorio oficial de paquetes de Python.\\n\\nlangchain-groq ‚Üí Es un paquete espec√≠fico que integra LangChain (un framework para construir aplicaciones basadas en modelos de lenguaje) con Groq, una empresa que proporciona hardware ultrarr√°pido para ejecutar modelos como LLaMA, Mixtral, etc.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d1fbf3",
      "metadata": {
        "id": "95d1fbf3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#from dotenv import load_dotenv\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "F8gZbQxAAFks"
      },
      "id": "F8gZbQxAAFks",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1f2ee71",
      "metadata": {
        "id": "c1f2ee71"
      },
      "outputs": [],
      "source": [
        "#VISION_MODEL_NAME=\"llama-3.2-11b-vision-preview\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Aca se esta generando la conexion a LLM.\n",
        "\n",
        "# ChatGroq es una clase\n",
        "#Temperatura= 0 (no seas tan verboso, se directo npo agregues mucho texto) // 1: Agrega mas detalle, mas diversidad (sinonimos y antonimos), pero puede alucinar\n",
        "\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    model_name=\"llama3-8b-8192\", # modelo de llama utilizado\n",
        "    groq_api_key=\"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\" #API Groq descargada\n",
        ")"
      ],
      "metadata": {
        "id": "NiH9ZGj-qu61"
      },
      "id": "NiH9ZGj-qu61",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27945111",
      "metadata": {
        "id": "27945111"
      },
      "outputs": [],
      "source": [
        "#Instruccion o PROMPT (lo que queremos que haga).\n",
        "# Deberiamos poner: \"Dada cierto informacion (manual) quiero que me respondas la siguiente pregunta\"\n",
        "\n",
        "#Template:  variable con texto\n",
        "# {recibo} : es una variable\n",
        "# {format_instructions} : Parser --> Indica a la LLM como se espera el output que generara este\n",
        "\n",
        "TEMPLATE=\"\"\"\n",
        "Dado la informacion del siguiente recibo, necesito que me extraigas la empresa emisora y el tipo de servicio\n",
        "{recibo}\n",
        "\n",
        "El formato de salida debe ser el siguiente:{format_instructions}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db2afd6a",
      "metadata": {
        "id": "db2afd6a"
      },
      "outputs": [],
      "source": [
        "# POO para el parser formato de salida --> Abstraen procesos de la vida real es la Clase:  Plantilla que se asemeja a la realidad\n",
        "\n",
        "class ContentGenerationScript(BaseModel):\n",
        "#Se indica que se espera de salida de la LLM, que quiero que me devuelva:\n",
        "    empresa_emisora: str = Field(description=\"Nombre de la empresa emisora\")\n",
        "    tipo_servicio: str = Field(description=\"Nombre del tipo de servicio\")\n",
        "\n",
        "#JsonOutputParser es otra clase, quiero que me devuelva la respuesta en un diccionario.\n",
        "# Todo se devuelve dentro de la variable \"parser\"\n",
        "parser= JsonOutputParser(pydantic_object=ContentGenerationScript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d828c58",
      "metadata": {
        "scrolled": true,
        "id": "2d828c58",
        "outputId": "6630f668-7178-49be-811a-218d8889a190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'recibo': '\\nN¬∫: FAC-2024-5582\\nFecha: 20 de mayo de 2024\\n\\nEMISOR:\\n‚Ä¢ Raz√≥n Social: TecnoSoluciones Innovadoras S.A. de C.V.\\n‚Ä¢ RFC: TSI-850301-KL4\\n‚Ä¢ Direcci√≥n: Calle Tecnol√≥gico #742, Guadalajara, Jalisco.\\n‚Ä¢ Contacto: ventas@tecnosoluciones.com | Tel. 33-5678-9012\\n\\nCLIENTE: Roberto S√°nchez Garc√≠a\\nCANTIDAD RECIBIDA: $3,800.00 MXN *(Tres mil ochocientos pesos 00/100 MXN)*\\n\\nüõ† SERVICIO PRESTADO:\\n‚Ä¢ Tipo de servicio: Mantenimiento preventivo de equipo de c√≥mputo (5 laptops y 3 impresoras).\\n‚Ä¢ Descripci√≥n detallada:\\n\\nLimpieza f√≠sica de hardware.\\n\\nActualizaci√≥n de software y antivirus.\\n\\nRevisi√≥n de componentes el√©ctricos.\\n\\nFORMA DE PAGO: Tarjeta de cr√©dito (VISA terminaci√≥n 7890)\\nREFERENCIA: *OP-TSI-2024-0055*\\n\\nIMPORTE DESGLOSADO:\\n\\nSubtotal: $3,275.86 MXN\\n\\nIVA (16%): $524.14 MXN\\n\\nTotal: $3,800.00 MXN\\n\\nFIRMA Y SELLO:\\n\\nAtentamente,\\nLic. Fernanda L√≥pez\\nGerente de Servicios T√©cnicos\\n\"TecnoSoluciones Innovadoras\"\\n\\nNota: *Este documento es v√°lido como comprobante fiscal (Art. 29-A del CFF).*\\n\\n',\n",
              " 'text': {'empresa_emisora': 'TecnoSoluciones Innovadoras S.A. de C.V.',\n",
              "  'tipo_servicio': 'Mantenimiento preventivo de equipo de c√≥mputo'}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=TEMPLATE,\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "# parser variable .get_format-...\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt, output_parser=parser)\n",
        "#Objeto que permite concatenar todo y permite ejecturar todo el proceso\n",
        "\n",
        "\n",
        "recibo=\"\"\"\n",
        "N¬∫: FAC-2024-5582\n",
        "Fecha: 20 de mayo de 2024\n",
        "\n",
        "EMISOR:\n",
        "‚Ä¢ Raz√≥n Social: TecnoSoluciones Innovadoras S.A. de C.V.\n",
        "‚Ä¢ RFC: TSI-850301-KL4\n",
        "‚Ä¢ Direcci√≥n: Calle Tecnol√≥gico #742, Guadalajara, Jalisco.\n",
        "‚Ä¢ Contacto: ventas@tecnosoluciones.com | Tel. 33-5678-9012\n",
        "\n",
        "CLIENTE: Roberto S√°nchez Garc√≠a\n",
        "CANTIDAD RECIBIDA: $3,800.00 MXN *(Tres mil ochocientos pesos 00/100 MXN)*\n",
        "\n",
        "üõ† SERVICIO PRESTADO:\n",
        "‚Ä¢ Tipo de servicio: Mantenimiento preventivo de equipo de c√≥mputo (5 laptops y 3 impresoras).\n",
        "‚Ä¢ Descripci√≥n detallada:\n",
        "\n",
        "Limpieza f√≠sica de hardware.\n",
        "\n",
        "Actualizaci√≥n de software y antivirus.\n",
        "\n",
        "Revisi√≥n de componentes el√©ctricos.\n",
        "\n",
        "FORMA DE PAGO: Tarjeta de cr√©dito (VISA terminaci√≥n 7890)\n",
        "REFERENCIA: *OP-TSI-2024-0055*\n",
        "\n",
        "IMPORTE DESGLOSADO:\n",
        "\n",
        "Subtotal: $3,275.86 MXN\n",
        "\n",
        "IVA (16%): $524.14 MXN\n",
        "\n",
        "Total: $3,800.00 MXN\n",
        "\n",
        "FIRMA Y SELLO:\n",
        "\n",
        "Atentamente,\n",
        "Lic. Fernanda L√≥pez\n",
        "Gerente de Servicios T√©cnicos\n",
        "\"TecnoSoluciones Innovadoras\"\n",
        "\n",
        "Nota: *Este documento es v√°lido como comprobante fiscal (Art. 29-A del CFF).*\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "result = chain.invoke({\"recibo\": recibo})\n",
        "# Aca estoy ejecutando la cadena y se le pasa la variable de entrada, \"recibo\"\n",
        "\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d5662a",
      "metadata": {
        "id": "17d5662a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f423b93-b4ea-4310-95aa-f5c9cebedae8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'empresa_emisora': 'TecnoSoluciones Innovadoras S.A. de C.V.',\n",
              " 'tipo_servicio': 'Mantenimiento preventivo de equipo de c√≥mputo'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "result['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7713cebb",
      "metadata": {
        "id": "7713cebb"
      },
      "outputs": [],
      "source": [
        "# tarea con el manual del camion:\n",
        "# Generar instruccion: dado cierto contexto (dar el contexto-->parseo del pdf, pedazo del manual) quiero que me respondas la siguiente pregunta (siendo la pregunta, una variable)\n",
        "# tanto la pregunta y el contexto tienen que ser dinamicos\n",
        "\n",
        "#Contexto : Pedazo de texto del manual. (Pedazo del manual)\n",
        "#Pregunta: Pregunta que haga el usuario.\n",
        "\n",
        "#Estas dos dinamicos, siempre va recibir como varible la instruccion (prompt)\n",
        "\n",
        "#Cambiar la instruccion, cambiar \"recibo\" por \"contexto\" // agregar la variabe \"pregunta\" y sacar un pedazo de texto de lo parseado.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}